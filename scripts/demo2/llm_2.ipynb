{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-community\n",
    "!pip install pypdf\n",
    "!pip install chromadb\n",
    "!pip install langchain\n",
    "!pip install langchain-groq\n",
    "!pip install sentence_transformers\n",
    "!pip install numpy\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yesil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Ram, also known as Rama, is a legendary king and the seventh avatar (incarnation) of the Hindu god Vishnu. He is a central figure in the Hindu epic, the Ramayana, and is revered as a symbol of virtue, duty, and righteousness.\n",
      "\n",
      "According to the Ramayana, Lord Ram was born in Ayodhya, the capital of the kingdom of Kosala, to King Dasaratha and Queen Kausalya. He was the eldest of four brothers, including Lakshmana, Bharata, and Shatrughna. Ram was known for his bravery, wisdom, and kindness, and was loved by all in the kingdom.\n",
      "\n",
      "The story of Lord Ram is a fascinating one. He was exiled to the forest for 14 years by his stepmother, Queen Kaikeyi, who wanted her son Bharata to become the king. During his exile, Ram's wife, Sita, was abducted by the demon king Ravana, who ruled over Lanka. Ram, along with his brother Lakshmana and the monkey god Hanuman, formed an army to rescue Sita and defeat Ravana.\n",
      "\n",
      "The battle between Ram and Ravana is a legendary one, with Ram ultimately emerging victorious and killing Ravana. After his victory, Ram returned to Ayodhya and was crowned king, ruling the kingdom with wisdom and justice.\n",
      "\n",
      "Lord Ram is revered for his many virtues, including:\n",
      "\n",
      "1. **Dharma** (righteousness): Ram is known for his unwavering commitment to duty and righteousness.\n",
      "2. **Maryada Purushottam** (ideal man): He is considered the ideal man, embodying all the qualities of a perfect human being.\n",
      "3. **Pativrata** (devotion to his wife): Ram's love and devotion to Sita are legendary, and he went to great lengths to rescue her from Ravana.\n",
      "4. **Brotherly love**: Ram's bond with his brothers, particularly Lakshmana, is a testament to the importance of sibling relationships.\n",
      "\n",
      "In Hinduism, Lord Ram is considered a symbol of good governance, and his reign is often referred to as the \"Ram Rajya,\" or the ideal kingdom. He is worshipped as a deity, and his birthday, known as Ram Navami, is celebrated with great fervor across India and other parts of the world.\n",
      "\n",
      "Overall, Lord Ram is a beloved figure in Hindu mythology, inspiring generations with his courage, wisdom, and unwavering commitment to duty and righteousness.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# .env içindeki GROQ_API_KEY değerini al\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Modeli başlat\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "# Sorgu gönder\n",
    "result = llm.invoke(\"Who is Lord Ram?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "chatbot_response() missing 1 required positional argument: 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    101\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHata oluştu: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[43mchatbot_response\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSomeone is threatening me on social media. What should I do?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: chatbot_response() missing 1 required positional argument: 'history'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import gradio as gr\n",
    "\n",
    "# .env dosyasını yükle\n",
    "load_dotenv()\n",
    "\n",
    "# LLM başlat\n",
    "def initialize_llm():\n",
    "    return ChatGroq(\n",
    "        temperature=0,\n",
    "        groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "        model_name=\"llama3-70b-8192\"\n",
    "    )\n",
    "\n",
    "# Vektör veritabanını oluştur\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(\"./data/\", glob='*.pdf', loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
    "    vector_db.persist()\n",
    "    return vector_db\n",
    "\n",
    "# LLM ve DB başlat\n",
    "llm = initialize_llm()\n",
    "db_path = \"./chroma_db/\"\n",
    "if not os.path.exists(db_path):\n",
    "    vector_db = create_vector_db()\n",
    "else:\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "\n",
    "retriever = vector_db.as_retriever()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Refine prompt'ları\n",
    "question_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant specialized in cyberbullying and mental health.\n",
    "\n",
    "Use the following context to answer the question:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"existing_answer\"],\n",
    "    template=\"\"\"\n",
    "We have an existing answer based on earlier context:\n",
    "{existing_answer}\n",
    "\n",
    "Now, with the new context below, improve or expand the answer if needed.\n",
    "If the context isn't helpful, keep the existing answer.\n",
    "\n",
    "New Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Refined Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# Chatbot fonksiyonu\n",
    "def chatbot_response(user_input, history):\n",
    "    if not user_input.strip():\n",
    "        return \"Lütfen geçerli bir mesaj girin.\"\n",
    "\n",
    "    try:\n",
    "        # refine chain_type doğru parametrelerle kuruldu\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"refine\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False,\n",
    "            chain_type_kwargs={\n",
    "                \"question_prompt\": question_prompt,\n",
    "                \"refine_prompt\": refine_prompt\n",
    "            }\n",
    "        )\n",
    "\n",
    "        response = qa_chain.run(user_input)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Hata oluştu: {str(e)}\"\n",
    "\n",
    "# Gradio arayüzü (isteğe bağlı stil)\n",
    "css = \"\"\"\n",
    ".gradio-container {\n",
    "    background-image: url('data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD...');\n",
    "    background-size: cover;\n",
    "    background-position: center;\n",
    "    background-repeat: no-repeat;\n",
    "    background-attachment: fixed;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Arayüz oluştur\n",
    "with gr.Blocks(css=css) as app:\n",
    "    gr.ChatInterface(\n",
    "        fn=chatbot_response,\n",
    "        title=\"Mental Health Chatbot\"\n",
    "    )\n",
    "\n",
    "app.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
