{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-community\n",
    "!pip install pypdf\n",
    "!pip install chromadb\n",
    "!pip install langchain\n",
    "!pip install langchain-groq\n",
    "!pip install sentence_transformers\n",
    "!pip install numpy\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yesil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Ram, also known as Rama, is a legendary king and the seventh avatar (incarnation) of the Hindu god Vishnu. He is a central figure in the Hindu epic, the Ramayana, and is revered as a symbol of virtue, duty, and righteousness.\n",
      "\n",
      "According to the Ramayana, Lord Ram was born in Ayodhya, the capital of the kingdom of Kosala, to King Dasaratha and Queen Kausalya. He was the eldest of four brothers, including Lakshmana, Bharata, and Shatrughna. Ram was known for his bravery, wisdom, and kindness, and was loved by all in the kingdom.\n",
      "\n",
      "The story of Lord Ram is a fascinating one. He was exiled to the forest for 14 years by his stepmother, Queen Kaikeyi, who wanted her son Bharata to become the king. During his exile, Ram's wife, Sita, was abducted by the demon king Ravana, who ruled over Lanka. Ram, along with his brother Lakshmana and the monkey god Hanuman, formed an army to rescue Sita and defeat Ravana.\n",
      "\n",
      "The battle between Ram and Ravana is a legendary one, with Ram ultimately emerging victorious and killing Ravana. After his victory, Ram returned to Ayodhya and was crowned king, ruling the kingdom with wisdom and justice.\n",
      "\n",
      "Lord Ram is revered for his many virtues, including:\n",
      "\n",
      "1. **Dharma** (righteousness): Ram is known for his unwavering commitment to duty and righteousness.\n",
      "2. **Maryada Purushottam** (ideal man): He is considered the ideal man, embodying all the qualities of a perfect human being.\n",
      "3. **Pativrata** (devotion to his wife): Ram's love and devotion to Sita are legendary, and he went to great lengths to rescue her from Ravana.\n",
      "4. **Brotherly love**: Ram's bond with his brothers, particularly Lakshmana, is a testament to the importance of sibling relationships.\n",
      "\n",
      "In Hinduism, Lord Ram is considered a symbol of good governance, and his reign is often referred to as the \"Ram Rajya,\" or the ideal kingdom. He is worshipped as a deity, and his birthday, known as Ram Navami, is celebrated with great fervor across India and other parts of the world.\n",
      "\n",
      "Overall, Lord Ram is a beloved figure in Hindu mythology, inspiring generations with his courage, wisdom, and unwavering commitment to duty and righteousness.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# .env içindeki GROQ_API_KEY değerini al\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Modeli başlat\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "# Sorgu gönder\n",
    "result = llm.invoke(\"Who is Lord Ram?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yesil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\yesil\\AppData\\Local\\Temp\\ipykernel_7464\\2796607472.py:27: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "C:\\Users\\yesil\\AppData\\Local\\Temp\\ipykernel_7464\\2796607472.py:29: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_db.persist()\n",
      "C:\\Users\\yesil\\AppData\\Local\\Temp\\ipykernel_7464\\2796607472.py:42: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "c:\\Users\\yesil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def initialize_llm():\n",
    "    return ChatGroq(\n",
    "        temperature=0,\n",
    "        groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "        model_name=\"llama3-70b-8192\"\n",
    "    )\n",
    "\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(\"./data2/\", glob='*.pdf', loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
    "    vector_db.persist()\n",
    "    return vector_db\n",
    "\n",
    "# Başlat\n",
    "llm = initialize_llm()\n",
    "db_path = \"./chroma_db/\"\n",
    "if not os.path.exists(db_path):\n",
    "    vector_db = create_vector_db()\n",
    "else:\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "\n",
    "retriever = vector_db.as_retriever()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Prompt'lar\n",
    "first_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a compassionate cyberbullying guide and mental health chatbot.\n",
    "Answer the following questions thoughtfully and with the official steps to take.\n",
    "\n",
    "{context}\n",
    "User: {question}\n",
    "Chatbot:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "normal_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "{context}\n",
    "User: {question}\n",
    "Chatbot:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Bu flag ilk mesajda True olacak\n",
    "first_message = {\"used\": False}\n",
    "\n",
    "# Chatbot cevabı\n",
    "def chatbot_response(user_input, history):\n",
    "    if not user_input.strip():\n",
    "        return \"Lütfen geçerli bir mesaj girin.\"\n",
    "\n",
    "    try:\n",
    "        prompt = first_prompt if not first_message[\"used\"] else normal_prompt\n",
    "        first_message[\"used\"] = True  # bir sonraki için artık normal prompt kullan\n",
    "\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            chain_type_kwargs={\"prompt\": prompt}\n",
    "        )\n",
    "\n",
    "        response = qa_chain.run(user_input)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Hata oluştu: {str(e)}\"\n",
    "\n",
    "# Gradio CSS\n",
    "css = \"\"\"\n",
    ".gradio-container {\n",
    "    background-image: url('data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD...');\n",
    "    background-size: cover;\n",
    "    background-position: center;\n",
    "    background-repeat: no-repeat;\n",
    "    background-attachment: fixed;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Arayüz\n",
    "with gr.Blocks(css=css) as app:\n",
    "    gr.ChatInterface(\n",
    "        fn=chatbot_response,\n",
    "        title=\"Mental Health Chatbot\"\n",
    "    )\n",
    "\n",
    "app.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
