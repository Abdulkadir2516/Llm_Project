Here is the news article with unnecessary parts removed:

Risks to children playing Roblox ‘deeply disturbing’, say researchers.

“Deeply disturbing” research exposes how easy it is for children to encounter inappropriate content and interact unsupervised with adults on the gaming platform Roblox.

Describing itself as “the ultimate virtual universe”, Roblox features millions of games and interactive environments, known collectively as “experiences”. In 2024, the platform had more than 85 million daily active users, an estimated 40% of whom are under 13.

Researchers created multiple Roblox accounts, registering them to fictional users aged five, nine, 10, 13 and 40-plus. The accounts interacted only with one another, and not with users outside the experiment, to ensure their avatars’ behaviours were not influenced in any way.

The report found that children as young as five were able to communicate with adults while playing games on the platform, and found examples of adults and children interacting with no effective age verification.

The report also found the avatar belonging to the 10-year-old’s account could access “highly suggestive environments”. These included a hotel space where they could view a female avatar wearing fishnet stockings gyrating on a bed and other avatars lying on top of each other in sexually suggestive poses, and a public bathroom space where characters were urinating and avatars could choose fetish accessories to dress up in.

Researchers found that their test avatars overheard conversations between other players verbalising sexual activity, as well as repeated slurping, kissing and grunting noises, when using the voice chat function.

They also found that a test avatar registered to an adult was able to ask for the five-year-old test avatar’s Snapchat details using barely coded language.

Roblox said it recognised “there are bad actors on the internet” but added this was “an issue that goes beyond Roblox and needs to be addressed through collaboration with governments and an industry-wide commitment to strong safety measures across all platforms”.

Stories shared by parents include that of a 10-year-old boy who was groomed by an adult he met on the platform, and a nine-year-old girl who started having panic attacks after seeing sexual content while gaming.

Damon De Ionno, the research director of Revealing Reality, said: “The new safety features announced by Roblox last week don’t go far enough. Children can still chat with strangers not on their friends list, and with 6 million experiences [on the platform], often with inaccurate descriptions and ratings, how can parents be expected to moderate?”

The crossbench peer and internet safety campaigner Beeban Kidron said the research exposed the platform’s “systematic failure to keep children safe”, adding: “This kind of user research should be routine for a product like Roblox.”

Matt Kaufman, the chief safety officer at Roblox, said: “Trust and safety are at the core of everything we do. We continually evolve our policies, technologies, and moderation efforts to protect our community, especially young people. This includes investing in advanced safety tools, working closely with experts and empowering parents and caregivers with robust controls and resources.