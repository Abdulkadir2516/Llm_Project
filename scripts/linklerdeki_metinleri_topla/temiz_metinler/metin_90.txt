Here is the main text of the article:

When we look at what causes poor mental health, we often think of stress, genetics, poverty or loneliness. These are all contributing factors, but there’s another, more hidden cause that isn’t talked about enough: abuse, especially during childhood.

Abuse isn’t an easy subject to raise or talk about. It brings up issues of gender dynamics – a colleague studying global sexual abuse told me: “The vast majority of perpetrators are men; the victims are equally boys and girls.” These are hard issues to think about, harder still to discuss and difficult to address. They challenge notions of safety, trust, family and community. But if we want to make progress in addressing poor mental health, we have to start here – with the truths we’d rather avoid.

The internet has fundamentally changed our world. Where once we worried about a child walking home from school alone or sleeping over at a friend’s house, now we have the entire online world to contend with. Grooming and exploitation no longer happen only in person – they happen on smartphones, in video games and through tablets handed over to keep kids entertained. And too often, the adults meant to protect children are far behind.

Recent research from Childlight, a child safety charity at the University of Edinburgh, has shown a steep rise in online grooming cases. It estimates that about 830,000 young people worldwide are at risk of social exploitation and abuse every day. This includes explicit photo sharing, sexual extortion, solicitation, deepfake images, pornography and grooming. Social media platforms, messaging apps and multiplayer games have become common avenues for abusers to target youngsters. They’ve been designed to be attractive and addictive to children, but largely without their safety in mind. And that puts the burden of protection unfairly on parents, many of whom don’t understand the risks – or aren’t even aware that they exist.

Take Roblox, a platform marketed as a child-friendly virtual playground. Behind its colourful, blocky graphics and simple games lies a reality far less innocent. A recent study examining interactions within the game found that through its open chat features, users were able to initiate contact with children as young as five, and were able to potentially speak with them over time before moving to other, less public platforms. Children could also see and hear sexual and suggestive content while playing various games. The researchers found that a test avatar registered to an adult could ask for a five-year-old’s test avatar’s Snapchat details on the platform. Just last month, a California man was accused of kidnapping and sexual conduct with a 10-year-old he met on Roblox. The surface looks benign. The danger lies underneath.

One thing that should be noted, too, is that even if physical contact never occurs, exposure to traumatic or sexually inappropriate content can still leave lasting mental scars. The internet and social media in particular have made it easier to access this kind of content, even if a child is never contacted by a coercive individual. Online abuse can take many forms, from exposure to sexual images and videos to inappropriate sexual and non-sexual language, extortion and solicitation.

In 2023, an estimated 19% of children aged 10 to 15 in England and Wales exchanged messages with someone online whom they had never met in real life. Nearly a third of eight- to 17-year-olds who game online say they chat to strangers while gaming. The vast majority of those interactions will be harmless, but when bad things do happen, many children feel isolated or unsupported: only half of children in a survey in England told their parents or teacher about harmful content they had seen online.

The same shame, confusion, fear and guilt that silences victims of abuse in the real world also mutes those suffering from exposure virtually. That silence can be deadly. Studies have shown that children who are groomed or coerced online often suffer from anxiety, depression, PTSD and suicidal thoughts. According to Samaritans, children and young people with histories of abuse are at far higher risk of self-harm and suicide.

We need to remove the stigma around abuse so that survivors of any age can speak up. We also need to better understand how quickly the landscape of risk is evolving. This means having open conversations with children, not just once but regularly. It means teaching them that they can talk to us about anything they see or experience online, without fear or shame. Tech companies need to be regulated by government to be accountable for creating safer environments. Just leaving it to voluntary initiatives doesn’t seem to be enough.

On 25 July, the Online Safety Act will be implemented in Britain, with clear safety rules for platforms to protect young people from harmful content, online abuse and sexual material. It is an important step forward in treating this issue with the urgency it deserves – just as we would with any other public health threat.