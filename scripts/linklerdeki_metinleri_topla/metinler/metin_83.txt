UK campaigners raise alarm over report of Meta plan to use automation for risk checks | Meta | The Guardian
Skip to main content
Skip to navigation
Close dialogue
1
/
1
Next image
Previous image
Toggle caption
Skip to navigation
Print subscriptions
Search jobs
Sign in
Eur
Europe edition
UK edition
US edition
Australia edition
International edition
The Guardian - Back to home
The Guardian
News
Opinion
Sport
Culture
Lifestyle
Show more
Hide expanded menu
News
View all News
World news
UK news
Climate crisis
Ukraine
Environment
Science
Global development
Football
Tech
Business
Obituaries
Opinion
View all Opinion
The Guardian view
Columnists
Cartoons
Opinion videos
Letters
Sport
View all Sport
Football
Cricket
Rugby union
Tennis
Cycling
F1
Golf
US sports
Culture
View all Culture
Books
Music
TV & radio
Art & design
Film
Games
Classical
Stage
Lifestyle
View all Lifestyle
Fashion
Food
Recipes
Love & sex
Health & fitness
Home & garden
Women
Men
Family
Travel
Money
Search input
google-search
Search
Support us
Print subscriptions
Search jobs
Holidays
Digital Archive
Guardian Licensing
About Us
The Guardian app
Video
Podcasts
Pictures
Newsletters
Today's paper
Inside the Guardian
Guardian Weekly
Crosswords
Wordiply
Corrections
Tips
Search input
google-search
Search
Search jobs
Holidays
Digital Archive
Guardian Licensing
About Us
World
UK
Climate crisis
Ukraine
Environment
Science
Global development
Football
Tech
Business
Obituaries
Organisations including the NSPCC and the Molly Rose Foundation wrote to Ofcom.
Photograph: Dzmitry Kliapitski/Alamy
View image in fullscreen
Organisations including the NSPCC and the Molly Rose Foundation wrote to Ofcom.
Photograph: Dzmitry Kliapitski/Alamy
Meta
UK campaigners raise alarm over report of Meta plan to use automation for risk checks
Ofcom ‘considering the concerns’ raised after claim that up to 90% of risk assessments will be carried out by AI
Dan Milmo
Global technology editor
Mon 9 Jun 2025 10.19 CEST
First published on Sun 8 Jun 2025 17.40 CEST
Share
Internet safety campaigners have urged the UK’s communications watchdog to limit the use of artificial intelligence in crucial risk assessments after a report that Mark Zuckerberg’s Meta was planning to automate checks.
Ofcom said it was “considering the concerns” raised by the campaigners’ letter, after
a report last month
that up to 90% of all risk assessments at the owner of Facebook, Instagram and WhatsApp would soon be carried out by AI.
Social media platforms are required under the UK’s Online Safety Act to gauge how harm could take place on their services and how they plan to mitigate those potential harms – with a particular focus on protecting child users and preventing illegal content from appearing. The risk assessment process is viewed as key aspect of the act.
Meta’s content moderation changes ‘hugely concerning’, says Molly Rose Foundation
Read more
In a letter to Ofcom’s chief executive, Melanie Dawes, organisations including the Molly Rose Foundation, the NSPCC and the Internet Watch Foundation described the prospect of AI-driven risk assessments as a “retrograde and highly alarming step”.
They said: “We urge you to publicly assert that risk assessments will not normally be considered as ‘suitable and sufficient’, the standard required by … the act, where these have been wholly or predominantly produced through automation.”
The letter also urged the watchdog to “challenge any assumption that platforms can choose to water down their risk assessment processes”.
A spokesperson for Ofcom said: “We’ve been clear that services should tell us who completed, reviewed and approved their risk assessment. We are considering the concerns raised in this letter and will respond in due course.”
skip past newsletter promotion
Sign up to
TechScape
Free weekly newsletter
A weekly dive in to how technology is shaping our lives
Enter your email address
Sign up
Privacy Notice:
Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our
Privacy Policy
. We use Google reCaptcha to protect our website and the Google
Privacy Policy
and
Terms of Service
apply.
after newsletter promotion
Don’t weaken online safety laws for UK-US trade deal, campaigners urge
Read more
Meta said the letter deliberately misstated the company’s approach on safety and it was committed to high standards and complying with regulations.
“We are not using AI to make decisions about risk,” said a Meta spokesperson. “Rather, our experts built a tool that helps teams identify when legal and policy requirements apply to specific products. We use technology, overseen by humans, to improve our ability to manage harmful content and our technological advancements have significantly improved safety outcomes.”
The Molly Rose Foundation organised the letter after the US broadcaster NPR reported last month that updates to Meta’s algorithms and new safety features would mostly be approved by an AI system and no longer scrutinised by staffers.
According to one former Meta executive who spoke to NPR anonymously, the change will allow the company to launch app updates and features on Facebook,
Instagram
and WhatsApp more quickly but will create “higher risks” for users, because potential problems are less likely to be prevented before a new product is released to the public.
NPR also reported that Meta was considering automating reviews for sensitive areas including youth risk and monitoring the spread of falsehoods.
Explore more on these topics
Meta
Artificial intelligence (AI)
Ofcom
Internet safety
Facebook
Instagram
WhatsApp
news
Share
Reuse this content
More on this story
More on this story
OpenAI boss accuses Meta of trying to poach staff with $100m sign-on bonuses
5d ago
Facebook and Instagram owner Meta to enable AI ad creation by end of next year
2 Jun 2025
UK’s top universities received £2.8m worth of funding from Meta last year
30 Apr 2025
EU fines Apple and Meta for breaching fair competition rules
23 Apr 2025
Gerry Adams considers suing Meta over alleged use of his books to train AI
10 Apr 2025
Meta faces £1.8bn lawsuit over claims it inflamed violence in Ethiopia
3 Apr 2025
Meta to stop targeting UK citizen with personalised ads after settling privacy case
22 Mar 2025
Jesse Eisenberg no longer wants to be ‘associated’ with Mark Zuckerberg
4 Feb 2025
Nick Clegg defends Meta’s removal of Facebook and Instagram factcheckers
22 Jan 2025
Meta to fire thousands of staff as Zuckerberg warns of ‘intense year’
15 Jan 2025
Most viewed
Most viewed
World
UK
Climate crisis
Ukraine
Environment
Science
Global development
Football
Tech
Business
Obituaries
News
Opinion
Sport
Culture
Lifestyle
Original reporting and incisive analysis, direct from the Guardian every morning
Sign up for our email
Help
Complaints & corrections
SecureDrop
Work for us
Privacy policy
Cookie policy
Terms & conditions
Contact us
All topics
All writers
Digital newspaper archive
Tax strategy
Facebook
YouTube
Instagram
LinkedIn
Newsletters
Advertise with us
Search UK jobs
Tips
Back to top
©
2025
Guardian News & Media Limited or its affiliated companies. All rights reserved.
(dcr)