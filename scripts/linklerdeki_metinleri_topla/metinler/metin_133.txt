Social media platforms face huge fines under UK’s new digital safety laws | Social media | The Guardian
Skip to main content
Skip to navigation
Close dialogue
1
/
1
Next image
Previous image
Toggle caption
Skip to navigation
Print subscriptions
Search jobs
Sign in
Eur
Europe edition
UK edition
US edition
Australia edition
International edition
The Guardian - Back to home
The Guardian
News
Opinion
Sport
Culture
Lifestyle
Show more
Hide expanded menu
News
View all News
World news
UK news
Climate crisis
Ukraine
Environment
Science
Global development
Football
Tech
Business
Obituaries
Opinion
View all Opinion
The Guardian view
Columnists
Cartoons
Opinion videos
Letters
Sport
View all Sport
Football
Cricket
Rugby union
Tennis
Cycling
F1
Golf
US sports
Culture
View all Culture
Books
Music
TV & radio
Art & design
Film
Games
Classical
Stage
Lifestyle
View all Lifestyle
Fashion
Food
Recipes
Love & sex
Health & fitness
Home & garden
Women
Men
Family
Travel
Money
Search input
google-search
Search
Support us
Print subscriptions
Search jobs
Holidays
Digital Archive
Guardian Licensing
About Us
The Guardian app
Video
Podcasts
Pictures
Newsletters
Today's paper
Inside the Guardian
Guardian Weekly
Crosswords
Wordiply
Corrections
Tips
Search input
google-search
Search
Search jobs
Holidays
Digital Archive
Guardian Licensing
About Us
UK
UK politics
Education
Media
Society
Law
Scotland
Wales
Northern Ireland
Ofcom’s codes of conduct for platforms include hiding children’s online profiles and locations by default from users they do not know.
Photograph: Jed Leicester/Rex/Shutterstock
View image in fullscreen
Ofcom’s codes of conduct for platforms include hiding children’s online profiles and locations by default from users they do not know.
Photograph: Jed Leicester/Rex/Shutterstock
Social media
This article is more than
3 months old
Social media platforms face huge fines under UK’s new digital safety laws
This article is more than 3 months old
Platforms must safeguard against content such as terrorist and child sexual abuse material under Online Safety Act
Dan Milmo
Global technology editor
Mon 17 Mar 2025 06.00 CET
Last modified on Mon 17 Mar 2025 12.38 CET
Share
Social media platforms face significant fines if they fail to implement robust measures in the UK to tackle illegal content, including fraud, terrorism, and child sexual abuse material, under new digital safety laws.
Tech companies must implement safeguards that take action against illegal harms such as encouraging suicide, extreme pornography and selling drugs.
From Monday, every site and app within the scope of the
Online Safety Act
, which covers more than 100,000 services from Facebook, Google and X to
Reddit
and OnlyFans, will be required to take steps to stop such content appearing or to take it down if it goes online.
The technology secretary, Peter Kyle, said the illegal content crackdown was “just the beginning”. “In recent years, tech companies have treated safety as an afterthought. That changes today,” he said.
Companies that breach the act face fines of up to £18m or 10% of worldwide revenue, which in the case of those such as Facebook’s owner, Meta, or Google would equate to billions of pounds. In extreme cases, services can also be taken down.
Ofcom, the UK watchdog overseeing the act, has
published codes of conduct
for tech platforms to follow in order to avoid breaching the legislation. The act lists 130 “priority offences”, or illegal content, that tech companies must tackle as a priority by ensuring their moderation systems are geared to deal with such material.
The codes of conduct include: hiding children’s online profiles and locations by default from users they do not know; introducing measures that allow women to block and mute users who are harassing or stalking them; establishing a reporting channel for organisations that can help deal with online fraud cases; and using “hash matching” technology, which is used to identify illegal images, to prevent sharing of terrorist content and non-consensual intimate images, or “revenge porn”.
What is the UK’s Online Safety Act and what powers will it provide?
Read more
Last year Ofcom
warned that tech companies had a “job of work”
to do in order to comply with the act and had yet to introduce all the measures needed to protect children and adults from harmful content. Speaking to the Guardian in December, Jon Higham, Ofcom’s online safety policy director, said many of the safety measures recommended by the watchdog were not being implemented by the largest and riskiest platforms.
“We don’t think any of them are doing all of the measures,” he said.
Ofcom also announced on Monday that it would ask online storage and filesharing services to outline what measures they have in place to prevent paedophiles from distributing child sexual abuse material via their platforms. Any company that does not respond, or appears to have inadequate measures in place, faces an investigation.
Mark Jones, a partner at the law firm Payne Hicks Beach, said the new illegal harms measures marked a “considerable sea change” in dealing with illegal or harmful content because they required tech companies to be proactive in identifying and removing dangerous material.
The Online Safety Act has been the subject of criticism by the US vice-president, JD Vance, who said last month that free speech in the UK was “in retreat”. However, Kyle has insisted the act will not be a bargaining chip in any negotiations with the Trump administration over the threat of tariffs being imposed on British exports to the US.
“Our online safety standards are not up for negotiation. They are on statute and they will remain,” Kyle
told LBC radio
last week. The British government’s view, which Keir Starmer reiterated in Washington last month, is that the act is about tackling criminality, not censoring debate.
Explore more on these topics
Social media
Internet safety
Digital media
Children
Ofcom
news
Share
Reuse this content
More on this story
More on this story
Ofcom announces new rules for tech firms to keep children safe online
24 Apr 2025
What are the Ofcom measures to protect children online – and will they work?
24 Apr 2025
Online forums being used to trade explicit images of local women, says charity
14 Feb 2025
Meta’s content moderation changes ‘hugely concerning’, says Molly Rose Foundation
28 Jan 2025
Stronger age checks to come into force for online pornography sites in UK
16 Jan 2025
UK online safety laws ‘unsatisfactory’ and ‘uneven’, says science minister
12 Jan 2025
Molly Russell’s father tells Starmer UK ‘going backwards’ on online safety
11 Jan 2025
Ofcom urged to act after US firm claims Roblox is ‘paedophile hellscape’
15 Oct 2024
Most viewed
Most viewed
UK
UK politics
Education
Media
Society
Law
Scotland
Wales
Northern Ireland
News
Opinion
Sport
Culture
Lifestyle
Original reporting and incisive analysis, direct from the Guardian every morning
Sign up for our email
Help
Complaints & corrections
SecureDrop
Work for us
Privacy policy
Cookie policy
Terms & conditions
Contact us
All topics
All writers
Digital newspaper archive
Tax strategy
Facebook
YouTube
Instagram
LinkedIn
Newsletters
Advertise with us
Search UK jobs
Tips
Back to top
©
2025
Guardian News & Media Limited or its affiliated companies. All rights reserved.
(dcr)